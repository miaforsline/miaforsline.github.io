[
  {
    "path": "posts/2022-01-20-robust-linear-models/",
    "title": "Robust Linear Models",
    "description": "Use `lm_robust()` to calculate heteroskedasticity-robust standard error values of housing prices",
    "author": [
      {
        "name": "Mia Forsline",
        "url": {}
      }
    ],
    "date": "2022-01-20",
    "categories": [
      "R",
      "Statistics"
    ],
    "contents": "\r\n\r\nContents\r\nLearning Goals\r\nSet up\r\nUse lm_robust() to run a bivariate regression with heteroskedasticity-robust standard errors\r\nPredict the housing price when nox = 7\r\n\r\nUse lm_robust() to run a multiple regression with heteroskedasticity-robust standard errors\r\nPredict the housing price when nox = 5 and rooms = 6\r\n\r\n\r\nLearning Goals\r\nUse estimatr to explore how lm_robust() can be used as a heteroskedasticity-robust estimator\r\nSet up\r\nload packages\r\nimport housing price data\r\nvisualize some of the data in a table\r\n\r\n\r\nshow\r\n\r\nlibrary(estimatr)\r\nlibrary(kableExtra)\r\nlibrary(tidyverse)\r\nlibrary(modelsummary)\r\n\r\nHPRICE2 <- read.csv(\"HPRICE2.csv\")\r\n\r\nkbl(head(HPRICE2)) %>%\r\n  kable_classic(full_width = F, html_font = \"Cambria\")\r\n\r\n\r\n\r\nprice\r\n\r\n\r\nnox\r\n\r\n\r\nrooms\r\n\r\n\r\nstratio\r\n\r\n\r\n24000\r\n\r\n\r\n5\r\n\r\n\r\n7\r\n\r\n\r\n15\r\n\r\n\r\n21599\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n18\r\n\r\n\r\n34700\r\n\r\n\r\n5\r\n\r\n\r\n7\r\n\r\n\r\n18\r\n\r\n\r\n33400\r\n\r\n\r\n5\r\n\r\n\r\n7\r\n\r\n\r\n19\r\n\r\n\r\n36199\r\n\r\n\r\n5\r\n\r\n\r\n7\r\n\r\n\r\n19\r\n\r\n\r\n28701\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n19\r\n\r\n\r\nUse lm_robust() to run a bivariate regression with heteroskedasticity-robust standard errors\r\n\r\n\r\nshow\r\n\r\nmodel1 <- lm_robust(formula = price ~ nox , data = HPRICE2)\r\nsummary(model1)\r\n\r\n\r\n\r\nCall:\r\nlm_robust(formula = price ~ nox, data = HPRICE2)\r\n\r\nStandard error type:  HC2 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value   Pr(>|t|) CI Lower CI Upper\r\n(Intercept)    39232     1451.2   27.03 3.858e-100    36381    42083\r\nnox            -3060      260.5  -11.75  2.536e-28    -3572    -2548\r\n             DF\r\n(Intercept) 504\r\nnox         504\r\n\r\nMultiple R-squared:  0.1731 ,   Adjusted R-squared:  0.1715 \r\nF-statistic: 137.9 on 1 and 504 DF,  p-value: < 2.2e-16\r\n\r\nPredict the housing price when nox = 7\r\nderive the standard error and 95% confidence interval\r\n\r\n\r\nshow\r\n\r\npredicted_price <- data.frame(nox=c(7)) \r\noutput <- predict(model1, newdata=predicted_price, se.fit=TRUE, interval='confidence')\r\n\r\navg_price <- round(output$fit[1], digits = 2)\r\nci_upper <- round(output$fit[3], digits = 2)\r\nci_lower <- round(output$fit[2], digits = 2)\r\nse <- round(output$se.fit[1], digits = 2)\r\n\r\n\r\n\r\nIf NOx = 7, we predict the average housing price to be approximately $17812.74 with a 95% confidence interval of 16709.01 to 18916.48 and a standard error of 561.79.\r\nUse lm_robust() to run a multiple regression with heteroskedasticity-robust standard errors\r\n\r\n\r\nshow\r\n\r\nmodel2 <- lm_robust(formula = price ~ nox + rooms, data = HPRICE2)\r\nsummary(model2)\r\n\r\n\r\n\r\nCall:\r\nlm_robust(formula = price ~ nox + rooms, data = HPRICE2)\r\n\r\nStandard error type:  HC2 \r\n\r\nCoefficients:\r\n            Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper\r\n(Intercept)   -16343     4809.5  -3.398 7.327e-04   -25792    -6893\r\nnox            -1646      265.1  -6.207 1.133e-09    -2166    -1125\r\nrooms           7635      650.4  11.738 2.749e-28     6357     8913\r\n             DF\r\n(Intercept) 503\r\nnox         503\r\nrooms       503\r\n\r\nMultiple R-squared:  0.5023 ,   Adjusted R-squared:  0.5003 \r\nF-statistic: 150.4 on 2 and 503 DF,  p-value: < 2.2e-16\r\n\r\nPredict the housing price when nox = 5 and rooms = 6\r\nderive the standard error and 95% confidence interval\r\n\r\n\r\nshow\r\n\r\npredicted_price=data.frame(nox=c(5), rooms=c(6))\r\noutput <- predict(model2, newdata=predicted_price, se.fit=TRUE, interval='confidence')\r\n\r\navg_price <- round(output$fit[1], digits = 2)\r\nci_upper <- round(output$fit[3], digits = 2)\r\nci_lower <- round(output$fit[2], digits = 2)\r\nse <- round(output$se.fit[1], digits = 2)\r\n\r\n\r\n\r\nIf NOx = 5 and the house has 6 rooms, we predict the average housing price to be approximately $21238.77 with a 95% confidence interval of 20648.73 to 21828.81 and a standard error of 300.32.\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-01-20-robust-linear-models/logo.png",
    "last_modified": "2024-05-09T13:18:29-07:00",
    "input_file": {},
    "preview_width": 512,
    "preview_height": 512
  },
  {
    "path": "posts/2022-01-07-ols-sim/",
    "title": "Assessing consistency of OLS amidst omitted variable bias",
    "description": "EDS 241: Environmental Policy Evaluation - Lab 1",
    "author": [
      {
        "name": "Mia Forsline",
        "url": {}
      }
    ],
    "date": "2022-01-06",
    "categories": [
      "R",
      "Statistics"
    ],
    "contents": "\r\n\r\nContents\r\nLearning Goals\r\nLoad necessary packages\r\nDemonstrate the consistency of OLS when the assumptions are upheld\r\nGraph the results\r\n\r\nDemonstrate the lack of OLS consistency due to omitted variables bias\r\nGraph the results\r\n\r\n\r\nLearning Goals\r\nUse a simulation to demonstrate the consistency of Ordinary Least Squares (OLS) under its 3 assumptions:\r\nexogeneity: X and µ are uncorrelated\r\nX and Y are independent and identically distributed\r\nlarge outliers in X and/or Y are rare (X and Y have finite fourth moments)\r\n\r\nUse a simulation to demonstrate what happens when assumptions are not upheld\r\nOLS becomes an unreliable estimator of the true population parameter \\(\\beta_1\\)\r\n\r\nLoad necessary packages\r\n\r\n\r\nshow\r\n\r\nlibrary(ggplot2)\r\nlibrary(huxtable)\r\nlibrary(ggthemes)\r\n\r\n\r\n\r\nDemonstrate the consistency of OLS when the assumptions are upheld\r\nestablish a large sample size of n = 10,000\r\ngenerate \\(X_1\\) and µ\r\ndefine \\(Y\\) and the population data using a bivariate population regression function\r\nuse a linear regression model to estimate \\(\\beta_0\\) and \\(\\beta_1\\) with an increasing sample size\r\n\r\n\r\nshow\r\n\r\nset.seed(420) \r\n\r\nbigN <- 10000 \r\n\r\nX1 <- runif(bigN, min = 0, max = 10)\r\nu <- rnorm(bigN, mean = 0, sd = 4) \r\n\r\n\r\nY <- 5 + 1.5*X1 + u \r\npopulation_data <- data.frame(X1, Y) \r\n\r\nmodel1 <- lm(formula = Y ~ X1, data = population_data)\r\nhuxreg(model1, error_pos=\"right\")\r\n\r\n\r\n     ────────────────────────────────────────────────────\r\n                                    (1)                  \r\n                      ───────────────────────────────────\r\n       (Intercept)           5.065 ***          (0.079)  \r\n       X1                    1.492 ***          (0.014)  \r\n                      ───────────────────────────────────\r\n       N                 10000                           \r\n       R2                    0.547                       \r\n       logLik           -27873.395                       \r\n       AIC               55752.791                       \r\n     ────────────────────────────────────────────────────\r\n       *** p < 0.001; ** p < 0.01; * p < 0.05.           \r\nColumn names: names, model1, NA\r\n\r\nshow\r\n\r\nbetahat_output <- matrix(ncol = 2, nrow = bigN)\r\n\r\nfor (n in 1:bigN) {\r\n  sample <- population_data[1:n,]\r\n  betahat_output[n,] <- lm(Y ~ X1, data = sample)$coefficients\r\n} \r\n\r\nn <- seq(1,bigN)\r\nbeta1hat <- betahat_output[,c(2)]\r\nforgraph <- data.frame(n , betahat_output[,c(2)])\r\n\r\n\r\n\r\nGraph the results\r\nas n increases, the OLS estimator \\(\\hat{\\beta_1}\\) (blue line) approaches the true population paramater \\(\\beta_1\\) (red line) = 1.5\r\n\r\n\r\nshow\r\n\r\nggplot(forgraph , aes(x=n, y=beta1hat)) + geom_line(size=0.5, color=\"blue\") +\r\n  geom_hline(yintercept=1.5, size=2, color=\"red\") +\r\n  labs(x=\"n\", y = \"Beta1hat\") + \r\n  ggthemes::theme_pander(base_size = 14) \r\n\r\n\r\n\r\nshow\r\n\r\nggsave(filename = \"logo.png\", width = 5, height = 4, units = \"in\", dpi = 300)\r\n\r\n\r\n\r\nDemonstrate the lack of OLS consistency due to omitted variables bias\r\ngenerate \\(X_2\\), which is correlated with \\(X_1\\)\r\nomit \\(X_2\\) from the model to cause omitted variable bias\r\ncalculate \\(\\hat{\\beta_1}\\)\r\n\r\n\r\nshow\r\n\r\nX2 = X1 +rnorm(bigN , mean=0 , sd=2.2) \r\n\r\nY <- 5 + 1.5*X1 + 10*X2 + u\r\npopulation_data <- data.frame(X1, Y)\r\n\r\nmodel1 <- lm(formula = Y ~ X1, data = population_data)\r\nhuxreg(model1, error_pos=\"right\")\r\n\r\n\r\n     ────────────────────────────────────────────────────\r\n                                    (1)                  \r\n                      ───────────────────────────────────\r\n       (Intercept)           4.960 ***          (0.448)  \r\n       X1                   11.596 ***          (0.077)  \r\n                      ───────────────────────────────────\r\n       N                 10000                           \r\n       R2                    0.692                       \r\n       logLik           -45267.984                       \r\n       AIC               90541.968                       \r\n     ────────────────────────────────────────────────────\r\n       *** p < 0.001; ** p < 0.01; * p < 0.05.           \r\nColumn names: names, model1, NA\r\n\r\nshow\r\n\r\nbetahat_output <- matrix(ncol = 2, nrow = bigN)\r\n\r\nfor (n in 1:bigN) {\r\n  sample <- population_data[1:n,]\r\n  betahat_output[n,] <- lm(Y ~ X1, data = sample)$coefficients\r\n} \r\n\r\nn <- seq(1,bigN)\r\nbeta1hat <- betahat_output[,c(2)]\r\nforgraph <- data.frame(n , betahat_output[,c(2)])\r\n\r\n\r\n\r\nCompute correlation between X1 and X2, and standard deviations\r\nCompute “probability limit” of Beta1_hat\r\n\r\n\r\nshow\r\n\r\ncor(X1,X2)\r\n\r\n\r\n[1] 0.7973109\r\n\r\nshow\r\n\r\nsd(X1)\r\n\r\n\r\n[1] 2.890737\r\n\r\nshow\r\n\r\nsd(X2)\r\n\r\n\r\n[1] 3.663339\r\n\r\nshow\r\n\r\n1.5 + 10*cor(X1,X2)*sd(X2)/sd(X1)\r\n\r\n\r\n[1] 11.60407\r\n\r\nGraph the results\r\nbecause of the omitted variables bias, \\(\\hat{\\beta_1}\\) hate never approaches the true \\(\\beta_1\\) value even when n becomes extremely large\r\n\r\n\r\nshow\r\n\r\nggplot(forgraph , aes(x=n, y=beta1hat)) + geom_line(size=0.5, color=\"blue\") +\r\n  geom_hline(yintercept=1.5, size=2, color=\"red\") +\r\n  labs(x=\"n\", y = \"Beta1hat\") + \r\n  ggthemes::theme_pander(base_size = 14) \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-01-07-ols-sim/logo.png",
    "last_modified": "2024-05-09T13:18:29-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-18-calenviroscreen/",
    "title": "From 2013 - 2021, California census tracts with higher poverty rates demonstrate worse air quality",
    "description": "EDS 222: Statistics for Environmental Data Science - Final Project",
    "author": [
      {
        "name": "Mia Forsline",
        "url": {}
      }
    ],
    "date": "2021-12-02",
    "categories": [
      "R",
      "Statistics"
    ],
    "contents": "\r\n\r\nContents\r\nResearch Question\r\nIntroduction\r\nStatistical Hypotheses\r\nData Description and Collection\r\n1. PM2.5\r\n2. Poverty\r\n\r\nMethods - Statistical Analysis Plan\r\nResults\r\nConclusion\r\nFuture Directions\r\nGitHub\r\n\r\nResearch Question\r\nFrom 2013 to 2021, does air quality (as measured by annual mean PM2.5 concentrations per census tract) vary with poverty rates (as measured by the percent of the population living below two times the federal poverty level per census tract) in California?\r\nIntroduction\r\nIn California, events like wildfires can greatly reduce air quality by releasing fine particles called particulate matter, or PM2.5 (Shi et al., 2019). PM2.5 refers to particles with diameters ≤ 2.5 µm, which are known to be hazardous for human health. PM2.5 is especially detrimental for human respiratory and cardiovascular health (Cleland et al., 2021). As California’s wildfires continue to worsen over time, it is becoming increasingly important to monitor air quality, PM2.5 concentrations, and their impacts on populations (Gupta et al., 2018).\r\nHowever, the environmental burden of poor air quality is not shared equally. For example, the San Joaquin Valley’s economically disadvantaged and ethnically diverse communities breathe some of the most polluted air in the nation (Cisneros et al., 2017). As a result, vulnerable communities such as Mexican American immigrant farm workers and their families experience disproportionately high rates of asthma attacks, hospital admissions, and other medical issues (Schwartz & Pepper, 2009). This inequitable pattern repeats itself in other states (Qian & Wu, 2019), the United States overall (Tessum et al., 2021), and even other countries (Li et al., 2018).\r\nWhile there are many possible ways to explore the inequity of air pollution in California, I specifically use annual mean PM2.5 to measure of air quality and poverty rate to quantify socioeconomic disparities. I expect to find a significant relationship between these two variables.\r\nStatistical Hypotheses\r\nMy null hypothesis (\\(H_0\\)) is that, in California, there is no relationship between annual mean PM2.5 concentrations per census tract and percent of the population living below twice the federal poverty line per census tract.\r\nMy alternative hypothesis (\\(H_A\\)) is that, in California, there is a relationship between annual mean PM2.5 concentrations per census tract and percent of the population living below twice the federal poverty line per census tract.\r\nData Description and Collection\r\n\r\n\r\nshow\r\n\r\nknitr::opts_chunk$set(echo = FALSE,\r\n                      message = FALSE, \r\n                      warning = FALSE, \r\n                      include = TRUE)\r\n#turn off scientific notation and select how many digits to round outputs to \r\noptions(\"scipen\" = 999, \"digits\" = 4)\r\n\r\n#import necessary libraries \r\nlibrary(tidyverse)\r\nlibrary(here)\r\nlibrary(gt)\r\nlibrary(xtable)\r\nlibrary(kableExtra)\r\n\r\n\r\n\r\n\r\n\r\nshow\r\n\r\n#read in data\r\nc1 <- read_csv(file = here(\"_posts\", \r\n                           \"2021-11-18-calenviroscreen\", \r\n                           \"CES\", \r\n                           \"CES_data\", \r\n                           \"ces1_2013.csv\"))\r\nc2 <- read_csv(file = here(\"_posts\", \r\n                           \"2021-11-18-calenviroscreen\", \r\n                           \"CES\", \r\n                           \"CES_data\", \r\n                           \"ces2_2014.csv\"))\r\nc3 <- read_csv(file = here(\"_posts\", \r\n                           \"2021-11-18-calenviroscreen\", \r\n                           \"CES\", \r\n                           \"CES_data\", \r\n                           \"ces3_2018.csv\"))\r\nc4 <- read_csv(file = here(\"_posts\", \r\n                           \"2021-11-18-calenviroscreen\", \r\n                           \"CES\", \r\n                           \"CES_data\", \r\n                           \"ces4_2021.csv\"))\r\n#clean data\r\n##select and rename necessary columns \r\n##add Year column \r\nc1_clean <- c1 %>% \r\n  select(c(\"ZIP Code\",\"Poverty\", \"PM2.5\")) %>% \r\n  mutate(Year = \"2013\") %>% \r\n  dplyr::rename(ZIP = \"ZIP Code\") %>% \r\n  mutate(ZIP = as.numeric(ZIP))\r\nc2_clean <- c2 %>% \r\n  select(c(\"Census Tract\", \"California County\", \"ZIP\", \"Longitude\", \"Latitude\", \"Poverty\", \"PM2.5\")) %>% \r\n  mutate(Year = \"2014\",\r\n         ZIP = as.numeric(ZIP))\r\nc3_clean <- c3 %>% \r\n  select(c(\"Census Tract\", \"California County\", \"ZIP\", \"Longitude\", \"Latitude\", \"Poverty\", \"PM2.5\")) %>% \r\n  mutate(Year = \"2018\",\r\n         ZIP = as.numeric(ZIP))\r\nc4_clean <- c4 %>% \r\n  select(c(\"Census Tract\", \"California County\", \"ZIP\", \"Longitude\", \"Latitude\", \"Poverty\", \"PM2.5\")) %>% \r\n  mutate(Year = \"2021\",\r\n         ZIP = as.numeric(ZIP))\r\n\r\n\r\n\r\n\r\n\r\nshow\r\n\r\n#fill in missing column data for c1 dataset so all datasets have the same columns \r\nc1_fill <- full_join(x = c2_clean, y = c1_clean, \r\n                     by = \"ZIP\", \r\n                     suffix = c(\".c2\", \".c1\")) %>%\r\n  select(c(\"Census Tract\", \r\n           \"California County\", \r\n           \"ZIP\", \r\n           \"Longitude\", \r\n           \"Latitude\", \r\n           \"Poverty.c1\", \r\n           \"PM2.5.c1\", \r\n           \"Year.c1\")) %>%\r\n  dplyr::rename(Poverty = \"Poverty.c1\",\r\n                PM2.5 = \"PM2.5.c1\",\r\n                Year = \"Year.c1\")\r\n\r\n\r\n\r\n\r\n\r\nshow\r\n\r\n#rbind datasets to create a single combined dataset with all 4 years of CalEnviroScreen data\r\njoined <- rbind(c4_clean, c3_clean, c2_clean, c1_fill) %>% \r\n  mutate(Year = as.factor(Year),\r\n         Year = factor(x = Year, levels = c(\"2013\", \"2014\", \"2018\", \"2021\"))) %>% \r\n  drop_na(Year) \r\n\r\n\r\n\r\nI downloaded 2013 - 2021 CalEnviroScreen (CES) data from the California Office of Environmental Health Hazard Assessment (OEHHA) and the California Open Data Portal:\r\nVersions 1.1 (Sept 2013)\r\nVersions 2.0 (Oct 2014)\r\nVersions 3.0 (June 2018)\r\nVersions 4.0 (Oct 2021)\r\nEach data set contains columns of environmental pollution burden indicators, including PM2.5, and population characteristics, including rates of poverty. Each census tract in California is represented as a row and assigned a value per environmental indicator and population characteristic. One thing to note is that due to developing technology over time, earlier data have different sample sizes and sampling techniques compared to newer data, which can complicate how we compare the data across time.\r\nOut of the myriad components of the CES data, I am interested in:\r\n1. PM2.5\r\nThe annual mean concentration of PM2.5 is a weighted average of measured monitor concentrations and satellite observations (ug/m3) over 3 years to avoid account for uneven sampling frequency. For example, the CES 1.1. report used data from 2007 - 2009 while the CES 4.0 report used 2015 - 2017. All reports used data from the California Air Resources Board’s Air Monitoring Network (AMN), while CES 3.0 and CES 4.0 also incorporated Satellite Remote Sensing Data.\r\nData were more likely to be high resolution around certain cities or localized areas, and not all cities had air monitoring stations. Locales with little to no data were either omitted or estimated using nearby locations’ data. For example, in CES 1.1, census tracts with centers > 50km away from the nearest air monitor were omitted. In CES 4.0, missing data was estimated using regression relationships with nearby sites.\r\nFor CES 1.1 - 3.0, the quarterly mean PM2.5 concentrations were estimated using ordinary kriging. For CES 4.0, overall PM2.5 annual mean concentrations were estimated for the center of each 1km x 1km grid cell using both the monitoring and satellite data in a weighted average. An inverse-distance weighting method was used, so grid cells close to monitors relied more heavily on monitor estimates while grid cells further from monitors relied more heavily on satellite data. Grid cells with monitors > 50km away relied solely on satellite data.\r\nThe quarterly estimates were then averaged to calculate annual means (Figure 1).\r\n\r\n\r\nshow\r\n\r\nggplot(data = joined, aes(x = PM2.5)) + \r\n  geom_histogram(aes(fill = Year), binwidth = 1) + \r\n  theme_classic() + \r\n  facet_wrap(~Year, ncol = 2) + \r\n  labs(x = expression(paste(\"Mean PM2.5 per census tract (µg/m\"^3~\")\")),\r\n       y = \"Frequency\") + \r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nFigure 1: 2013 - 2021 mean PM2.5 in California was not normally distributed. In 2013 (n = 8,151), 2014 (n = 7,847), 2018 (n = 7,938), and 2021 (n = 7,960), the annual mean concentrations of PM2.5 (µg/m3) per census tract were 11.52, 10.01, 10.38, and 10.15 respectively. Data was sourced from CalEnviroScreen 1.1 - 4.0 (https://oehha.ca.gov/).\r\n\r\n\r\n\r\n2. Poverty\r\nThe percent of the population living below two times the federal poverty level was calculated using a 5-year estimate to produce more reliable results for geographic areas with small populations. For example, the CES 1.1 report used a 5-year estimate from 2007 - 2011 data while the CES 4.0 report used a 5-year estimate from 2015 - 2019 data. Poverty data came from the American Community Survey.\r\nCES defined poverty as twice below the federal poverty line to account for California’s high cost of living relative to other states and because the federal poverty threshold has not changed since the 1980s despite the cost of living increasing over time. The percent per census tract was calculated by individuals living below 200% the poverty level per census tract / total individuals living below 200% of the poverty level (Figure 2). Standard error was calculated to determine the reliability of the calculated poverty rate. Census tracts with unreliable estimates were assigned no value for poverty rate.\r\n\r\n\r\nshow\r\n\r\nggplot(data = joined, aes(x = Poverty)) + \r\n  geom_histogram(aes(fill = Year), binwidth = 5) + \r\n  theme_classic() + \r\n  facet_wrap(~Year, ncol = 2) + \r\n  labs(x = \"Poverty rate per census tract (%)\", \r\n       y = \"Frequency\")\r\n\r\n\r\n\r\n\r\nFigure 2: 2013 - 2021 poverty rates in California were not normally distributed. In 2013 (n = 8,151), 2014 (n = 7,847), 2018 (n = 7,938), and 2021 (n = 7,960), the mean percentages of the population per census tract living below two times the federal poverty level were 34.24%, 35.28%, 36.39%, and 31.34% respectively. Data was sourced from CalEnviroScreen 1.1 - 4.0 (https://oehha.ca.gov/).\r\n\r\n\r\n\r\nMethods - Statistical Analysis Plan\r\nTo assess if, in California from 2013 - 2021, air quality varied with poverty rates, I ran a linear regression of PM2.5 ~ Poverty for each year (e.g., 2013, 2014, 2018, 2021). This analysis is appropriate to describe how air quality might be changing with respect to poverty rates. Running multiple regressions over different years can help determine how this relationship could be changing over time.\r\nThis method is limited by the fact that I am only including one independent variable (Poverty) in the model. In other words, this analysis is vulnerable to omitted variables bias because it is likely that there are many different factors in addition to poverty that influence air quality. Nevertheless, this is a solid starting point for unraveling those complex relationships.\r\nResults\r\n\r\n\r\nshow\r\n\r\nmod1 <- lm(PM2.5 ~ Poverty, data = c1)\r\nsum1 <- summary(mod1)\r\n\r\nmod2 <- lm(PM2.5 ~ Poverty, data = c2)\r\nsum2 <- summary(mod2)\r\n\r\nmod3 <- lm(PM2.5 ~ Poverty, data = c3)\r\nsum3 <- summary(mod3)\r\n\r\nmod4 <- lm(PM2.5 ~ Poverty, data = c4)\r\nsum4 <- summary(mod4)\r\n\r\n\r\n\r\nFor all time periods, annual mean PM2.5 concentrations were significantly influenced by the poverty rate (Figure 3). In 2013, PM2.5 increased by 0.0352 µg/m3 as the poverty rate increased by 1% (p-value < 0.001, sd = 0.0044). In 2014, PM2.5 increased by 0.0279 µg/m3 as the poverty rate increased by 1% (p-value < 0.001, sd = 0.0014). In 2018, PM2.5 increased by 0.0299 µg/m3 as the poverty rate increased by 1% (p-value < 0.001, sd = 0.0014). In 2021, PM2.5 increased by 0.0286 µg/m3 as the poverty rate increased by 1% (p-value < 0.001, sd = 0.0013). These results support my hypothesis that mean PM2.5 and poverty in California are positively related.\r\nOver time, the relationship between mean PM2.5 and poverty rate has remained fairly stable with the slope only varying from 0.0279 to 0.0352.\r\n\r\n\r\nshow\r\n\r\njoined <- joined %>% \r\n  drop_na(Poverty, PM2.5)\r\n\r\nggplot(data = joined, aes(x = Poverty, y = PM2.5)) +\r\n  geom_point(aes(color = Year), alpha = 0.05) + \r\n  geom_smooth(method='lm', \r\n              formula= y~x,\r\n              size=1, \r\n              color = \"black\") + \r\n  theme_classic()+ \r\n  labs(x = \"Poverty rate (%)\",\r\n       y = expression(paste\r\n                       (\"Mean PM2.5 (µg/m\"^3~\")\"))) +\r\n  facet_wrap(.~Year, ncol = 2) + \r\n  theme(legend.position = \"none\")\r\n\r\n\r\n\r\n\r\nFigure 3: Air quality significantly associates poverty in California. In 2013 (n = 8,151), 2014 (n = 7,847), 2018 (n = 7,938), and 2021 (n = 7,960), as poverty rates increase in California, mean PM2.5 increases and air quality deteriorates (p-value <<< 0.001).\r\n\r\n\r\n\r\nConclusion\r\nAs expected, I found a statistically significant relationship between air quality and poverty rates in California during 2013, 2014, 2018, and 2021. For all four years, annual mean concentrations of PM2.5 (µg/m3) increased as the percent of people living below twice the federal poverty level increased (Figure 3). In other words, air quality was on average lower in census tracts with higher poverty rates. These findings supported my hypothesis and corroborated prior research that has identified PM2.5 disparities based on socioeconomic factors in California (Mousavi et al., 2021). This analysis also emphasizes the importance of an environmental justice lens when investigating issues such as air quality.\r\nFuture Directions\r\nWhile my analysis focused on four specific years of comprehensive CalEnviroScreen data, it would be interesting to expand the time frame to before 2013 because 2013 is when California’s cap-and-trade program was initiated. During this time, there is evidence that while overall greenhouse gases were reduced in California, socioeconomically disadvantaged communities actually experienced emission increases (Cushing et al., 2018).\r\nGitHub\r\nThe full code can be accessed here.\r\n\r\n\r\n\r\nCisneros, R., Brown, P., Cameron, L., Gaab, E., Gonzalez, M., Ramondt, S., Veloz, D., Song, A., & Schweizer, D. (2017). Understanding Public Views about Air Quality and Air Pollution Sources in the San Joaquin Valley, California. Journal of Environmental and Public Health, 2017, e4535142. https://doi.org/10.1155/2017/4535142\r\n\r\n\r\nCleland, S. E., Serre, M. L., Rappold, A. G., & West, J. J. (2021). Estimating the Acute Health Impacts of Fire-Originated PM2.5 Exposure During the 2017 California Wildfires: Sensitivity to Choices of Inputs. GeoHealth, 5(7), e2021GH000414. https://doi.org/10.1029/2021GH000414\r\n\r\n\r\nCushing, L., Blaustein-Rejto, D., Wander, M., Pastor, M., Sadd, J., Zhu, A., & Morello-Frosch, R. (2018). Carbon trading, co-pollutants, and environmental equity: Evidence from California’s cap-and-trade program (20112015). PLOS Medicine, 15(7), e1002604. https://doi.org/10.1371/journal.pmed.1002604\r\n\r\n\r\nGupta, P., Doraiswamy, P., Levy, R., Pikelnaya, O., Maibach, J., Feenstra, B., Polidori, A., Kiros, F., & Mills, K. C. (2018). Impact of California Fires on Local and Regional Air Quality: The Role of a Low-Cost Sensor Network and Satellite Observations. GeoHealth, 2(6), 172–181. https://doi.org/10.1029/2018GH000136\r\n\r\n\r\nLi, V. O., Han, Y., Lam, J. C., Zhu, Y., & Bacon-Shone, J. (2018). Air pollution and environmental injustice: Are the socially deprived exposed to more PM2.5 pollution in Hong Kong? Environmental Science & Policy, 80, 53–61. https://doi.org/10.1016/j.envsci.2017.10.014\r\n\r\n\r\nMousavi, A., Yuan, Y., Masri, S., Barta, G., & Wu, J. (2021). Impact of 4th of July Fireworks on Spatiotemporal PM2.5 Concentrations in California Based on the PurpleAir Sensor Network: Implications for Policy and Environmental Justice. International Journal of Environmental Research and Public Health, 18(11), 5735. https://doi.org/10.3390/ijerph18115735\r\n\r\n\r\nQian, X., & Wu, Y. (2019). Assessment for health equity of PM2.5 exposure in bikeshare systems: The case of Divvy in Chicago. Journal of Transport & Health, 14, 100596. https://doi.org/10.1016/j.jth.2019.100596\r\n\r\n\r\nSchwartz, N. A., & Pepper, D. (2009). Childhood Asthma, Air Quality, and Social Suffering Among Mexican Americans in California’s San Joaquin Valley: “Nobody Talks to Us Here”. Medical Anthropology, 28(4), 336–367. https://doi.org/10.1080/01459740903303944\r\n\r\n\r\nShi, H., Jiang, Z., Zhao, B., Li, Z., Chen, Y., Gu, Y., Jiang, J. H., Lee, M., Liou, K.-N., Neu, J. L., Payne, V. H., Su, H., Wang, Y., Witek, M., & Worden, J. (2019). Modeling Study of the Air Quality Impact of Record-Breaking Southern California Wildfires in December 2017. Journal of Geophysical Research: Atmospheres, 124(12), 6554–6570. https://doi.org/10.1029/2019JD030472\r\n\r\n\r\nTessum, C. W., Paolella, D. A., Chambliss, S. E., Apte, J. S., Hill, J. D., & Marshall, J. D. (2021). PM 2.5 polluters disproportionately and systemically affect people of color in the United States. Science Advances, 7(18), eabf4491. https://doi.org/10.1126/sciadv.abf4491\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-11-18-calenviroscreen/logo.png",
    "last_modified": "2024-05-09T13:18:29-07:00",
    "input_file": {},
    "preview_width": 400,
    "preview_height": 300
  },
  {
    "path": "posts/2021-10-24-eds223houston/",
    "title": "Spatial analysis of 2020 Houston power outages due to extreme winter storms",
    "description": "EDS 223: Spatial Analysis - Assignment 2",
    "author": [
      {
        "name": "Mia Forsline",
        "url": {}
      }
    ],
    "date": "2021-10-24",
    "categories": [
      "R",
      "Spatial Analysis"
    ],
    "contents": "\r\n\r\nContents\r\nLearning objectives\r\nIntroduction\r\nLoad necessary packages\r\nLoad and explore data\r\nDefine a function to load the DNB dataset from VNP46A1 granules\r\nInvoke the function to read in all 4 datasets\r\nCombine the data into 2 datasets\r\nCreate exploratory plots for night lights intensity before and after the storm\r\n\r\nCreate a blackout mask\r\nVectorize the mask and fix invalid geometries\r\nCrop the vectorized map to our ROI\r\n\r\nRead in roads Data\r\nRead in buildings data\r\nRead in census tract data\r\nMerge the datasets\r\nQuestion 1: How many residential buildings were without power on 2021-02-16?\r\nVisualize buildings where the blackout occurred\r\n\r\nConclusion\r\nGitHub\r\n\r\nLearning objectives\r\nLoad vector data\r\nLoad raster data\r\nSimple raster operations\r\nSimple geoprocessing / vector operations\r\nSpatial joins\r\nIntegrating SQL into an RMD\r\nIntroduction\r\nDuring February 2021, Texas experienced three extreme winter storms on February 10-11, February 13-17, and Februrary 15-20 that caused power outages in Houston’s residential areas. We are interested in quantifying the severity of those power outages by calculating the number of Houston homes that lost power due to the first two storms.\r\nTo do so, we are used NASA’s VNP46A1 data product from the Visible Infrared Imaging Radiometer Suite (VIIRS) to examine night lights image data from February 7-16. We used four VIIRS data tiles to study the Houston area.\r\nWe also incorporated OpenStreetMap roads and building data to account for light emitted from traffic and buildings.\r\nWe defined an area as having experienced a blackout if we calculate a difference in night lights intensity greater than 200 nW cm-2 sr-1.\r\nLoad necessary packages\r\n\r\n\r\nshow\r\n\r\nlibrary(sf)\r\nlibrary(stringr)\r\nlibrary(stars)\r\nlibrary(rgdal)\r\nlibrary(dplyr)\r\nlibrary(tmap)\r\nlibrary(lintr)\r\nlibrary(rosm)\r\n\r\n\r\n\r\nLoad and explore data\r\nDefine a function to load the DNB dataset from VNP46A1 granules\r\n\r\n\r\nshow\r\n\r\nread_dnb <- function(file_name) {\r\n\r\n  dataset_name <- \"//HDFEOS/GRIDS/VNP_Grid_DNB/Data_Fields/DNB_At_Sensor_Radiance_500m\"\r\n\r\n  h_string <- gdal_metadata(file_name)[199]\r\n  v_string <- gdal_metadata(file_name)[219]\r\n\r\n  tile_h <- as.integer(str_split(h_string, \"=\", simplify = TRUE)[[2]])\r\n  tile_v <- as.integer(str_split(v_string, \"=\", simplify = TRUE)[[2]])\r\n\r\n  west <- (10 * tile_h) - 180\r\n  north <- 90 - (10 * tile_v)\r\n  east <- west + 10\r\n  south <- north - 10\r\n\r\n  delta <- 10 / 2400\r\n\r\n  dnb <- read_stars(file_name, sub = dataset_name, quiet = TRUE)\r\n\r\n  st_crs(dnb) <- st_crs(4326)\r\n  st_dimensions(dnb)$x$delta <- delta\r\n  st_dimensions(dnb)$x$offset <- west\r\n  st_dimensions(dnb)$y$delta <- -delta\r\n  st_dimensions(dnb)$y$offset <- north\r\n\r\n  return(dnb)\r\n}\r\n\r\n\r\n\r\nInvoke the function to read in all 4 datasets\r\n\r\n\r\nshow\r\n\r\nfile_name <- \"data/VNP46A1.A2021038.h08v05.001.2021039064328.h5\"\r\ndnb_38_v05 <- read_dnb(file_name = file_name)\r\n\r\nfile_name <- \"data/VNP46A1.A2021038.h08v06.001.2021039064329.h5\"\r\ndnb_38_v06 <- read_dnb(file_name = file_name)\r\n\r\nfile_name <- \"data/VNP46A1.A2021047.h08v05.001.2021048091106.h5\"\r\ndnb_47_v05 <- read_dnb(file_name = file_name)\r\n\r\nfile_name <- \"data/VNP46A1.A2021047.h08v06.001.2021048091105.h5\"\r\ndnb_47_v06 <- read_dnb(file_name = file_name)\r\n\r\n\r\n\r\nCombine the data into 2 datasets\r\ndnb_38 is data from before the storm\r\ndnb_47 is data from after the storm\r\n\r\n\r\nshow\r\n\r\nx1 <- dnb_38_v05\r\nx2 <- dnb_38_v06\r\ndnb_38 <- st_mosaic(x1, x2)\r\n\r\nx3 <- dnb_47_v05\r\nx4 <- dnb_47_v06\r\ndnb_47 <- st_mosaic(x3, x4)\r\n\r\n\r\n\r\nCreate exploratory plots for night lights intensity before and after the storm\r\nNote: This is a crude data analysis of the “DNB_At_Sensor_Radiance_500m” dataset, which contains values as seen from space. There is no correction for stray light, moonshine, cloud presence, or any other confounding variables As a result, it is possible we have surprising outliers and regions that systemically actually appear to be brighter from space after the storm.\r\n\r\n\r\nshow\r\n\r\nplot(dnb_38,\r\n     ylim = c(29, 30.5),\r\n     xlim = c(-94.5, -96.5),\r\n     breaks = seq(0, 2000, length.out = 1000))\r\n\r\n\r\ndownsample set to c(9,9)\r\n\r\n\r\nFigure 1: Night lights intensity in Houston, TX before the storm.\r\n\r\n\r\n\r\n\r\n\r\nshow\r\n\r\nplot(dnb_47,\r\n     ylim = c(29, 30.5),\r\n     xlim = c(-94.5, -96.5),\r\n     breaks = seq(0, 2000, length.out = 1000))\r\n\r\n\r\ndownsample set to c(9,9)\r\n\r\n\r\nFigure 2: Night lights intensity in Houston, TX after the storm.\r\n\r\n\r\n\r\nCreate a blackout mask\r\nTo find the difference, we subtract night lights intensity after the storm (which is less bright) from night lights intensity before the storm (which is brighter)\r\nNext, we mark all observations that did not experience a blackout as NA\r\n\r\n\r\nshow\r\n\r\ndifference <- (dnb_38 - dnb_47) > 200\r\ndifference[difference == FALSE] <- NA\r\n\r\n\r\n\r\nVectorize the mask and fix invalid geometries\r\n\r\n\r\nshow\r\n\r\ndiff_vector <- st_as_sf(difference)\r\ndiff_vector <- st_make_valid(diff_vector)\r\n\r\n\r\n\r\nCrop the vectorized map to our ROI\r\nCreate a bounding box for the Houston area\r\nConvert the bounding box to a sf\r\nProject the bounding box to WGS 84\r\nCrop the vectorized map to the Houston bounding box\r\nProject the cropped, vectorized map to NAD 83\r\n\r\n\r\nshow\r\n\r\nhouston <- st_polygon(list(rbind(c(-96.5, 29),\r\n                                 c(-96.5, 30.5),\r\n                                 c(-94.5, 30.5),\r\n                                 c(-94.5, 29),\r\n                                 c(-96.5, 29))))\r\nhouston <- st_sfc(houston)\r\nhouston <- houston %>%\r\n  st_set_crs(4326)\r\n\r\ndiff_cropped <- diff_vector[houston, op = st_intersects]\r\ndiff_cropped <- diff_cropped %>%\r\n  st_transform(3083)\r\n\r\n\r\n\r\nRead in roads Data\r\nUse SQL to read in the highways data\r\nProject highways to NAD 83\r\nCreate and dissolve 200m buffers around the highways\r\n\r\n\r\nshow\r\n\r\nquery <- \"SELECT * FROM gis_osm_roads_free_1 WHERE fclass='motorway'\"\r\nhighways <- st_read(\"data/gis_osm_roads_free_1.gpkg\", query = query, quiet = TRUE)\r\nhighways <- highways %>%\r\n  st_transform(3083)\r\n\r\nhwy_buff_200m  <- st_buffer(highways, dist =  200)\r\nhwy_buff_200m <- st_union(hwy_buff_200m)\r\n\r\n\r\n\r\nRead in buildings data\r\nUse SQL to read in the buildings data\r\nProject buildings to NAD 83\r\nNote: buildings contains residential, apartments, house, static_caravan, and detached types\r\n\r\n\r\nshow\r\n\r\nquery <- \"SELECT *\r\nFROM gis_osm_buildings_a_free_1\r\nWHERE (type IS NULL AND name IS NULL)\r\nOR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\"\r\n\r\nbuildings <- st_read(\"data/gis_osm_buildings_a_free_1.gpkg\", query = query, quiet = TRUE)\r\nbuildings <- buildings %>%\r\n  st_transform(3083)\r\n\r\n\r\n\r\nRead in census tract data\r\nRead in both geometries and income data\r\nExtract median income field and GEOID field from acs_income\r\nJoin the datasets\r\nProject the joined dataset to NAD 83\r\nProject Houston bounding box to NAD 83\r\nCrop the joined data to the Houston bounding box\r\n\r\n\r\nshow\r\n\r\nacs_geoms <- st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\",\r\n                     layer = \"ACS_2019_5YR_TRACT_48_TEXAS\",\r\n                     quiet = TRUE)\r\nacs_income <- st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\",\r\n                      layer = \"X19_INCOME\", \r\n                      quiet = TRUE)\r\n\r\nmedian_income <- acs_income[c(\"GEOID\", \"B19013e1\")]\r\ngeo_id <- acs_income[c(\"GEOID\")]\r\n\r\ngeoms_income <- left_join(acs_geoms, acs_income, by = c(\"GEOID_Data\" = \"GEOID\"))\r\ngeoms_income <- geoms_income %>%\r\n  st_transform(3083)\r\n\r\nhouston <- houston %>%\r\n  st_transform(3083)\r\n\r\ngeoms_income_cropped <- geoms_income[houston, op = st_intersects]\r\n\r\n\r\n\r\nMerge the datasets\r\nRemove highway 200m buffer from the vectorized blackout mask of Houston so our area of interest ignores highways\r\n\r\n\r\nshow\r\n\r\nno_hwy <- st_difference(diff_cropped, hwy_buff_200m)\r\n\r\n\r\n\r\nQuestion 1: How many residential buildings were without power on 2021-02-16?\r\nUse spatial subsetting to find all residential buildings in the blackout areas\r\nCrop all residential buildings based on no_hwy (which is our area of interest)\r\nExtract the number of rows (aka the number of buildings that experienced a blackout )\r\n\r\n\r\nshow\r\n\r\nbuildings_blackout <- buildings[no_hwy, op = st_intersects]\r\nq1_ans <- nrow(buildings_blackout)\r\n\r\n\r\n\r\nThere were 157411 residential buildings without power on 2021-02-16.\r\nVisualize buildings where the blackout occurred\r\nCreated a map of residential buildings that experienced a blackout (res)\r\nAdded res on top of a base map of the Houston area\r\n\r\n\r\nshow\r\n\r\nres <- tm_shape(buildings_blackout) +\r\n  tm_borders()\r\n\r\npt1 <- st_point(c(-96.5, 29))\r\npt2 <- st_point(c(-96.5, 30.5))\r\npt3 <- st_point(c(-94.5, 30.5))\r\npt4 <- st_point(c(-94.5, 29))\r\ncoords <- list(rbind(pt1, pt2, pt3, pt4, pt1))\r\npolygon <- st_polygon(x = coords)\r\nhouston <- st_sfc(polygon, crs = \"EPSG:4326\")\r\n\r\nhouston_bbox <- st_bbox(houston)\r\nhouston_map <- osm.raster(houston_bbox)\r\n\r\ntm_shape(houston_map) +\r\ntm_rgb() + \r\nres\r\n\r\n\r\n\r\n\r\nFigure 3: Approximately 157,411 residential buildings in Houston, TX were affected by the February 2021 storm.\r\n\r\n\r\n\r\nshow\r\n\r\ntmap_save(filename = \"houston.jpg\", width = 8, height = 5, units = \"in\", dpi = 300)\r\n\r\nbb_geoms_income <- st_join(buildings_blackout, geoms_income,\r\n                           join = st_intersects,\r\n                           left = TRUE)\r\n\r\n\r\n\r\nConclusion\r\nIn conclusion, we identified 157411 residential buildings in Houston without power due to the severe February 2021 storms. While night lights intensity may just be one way to measure the impact of these events, this method illustrates the vast potential of remotely sensed data from sources such as the Visible Infrared Imaging Radiometer Suite (VIIRS) aboard the Suomi satellite.\r\nGitHub\r\nFull code for this assignment can be found here.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-24-eds223houston/houston.jpg",
    "last_modified": "2024-05-09T13:18:28-07:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-10-07-eds223cartography/",
    "title": "Exploring basic cartography using `sf` and `tmap`",
    "description": "EDS 223: Spatial Analysis - Assignment 1",
    "author": [
      {
        "name": "Mia Forsline",
        "url": {}
      }
    ],
    "date": "2021-10-07",
    "categories": [
      "R",
      "Spatial Analysis"
    ],
    "contents": "\r\n\r\nContents\r\nLearning Goals:\r\nLoad necessary packages\r\nLoad, subset, and explore Asia data from spData world data\r\nSpecify class intervals\r\nAdd a graticule if necessary\r\nHistogram of gdpPercap to choose breaks style\r\nPlot finished Asia map\r\nGitHub\r\n\r\nLearning Goals:\r\nLearn the basics of map design\r\nLearn how to load geospatial data\r\nLearn how to inspect geospatial data\r\nPlot geospatial data\r\nLoad necessary packages\r\n\r\n\r\nshow\r\n\r\nknitr::opts_chunk$set(echo = TRUE, \r\n                      message = FALSE,\r\n                      warning = FALSE,\r\n                      include = TRUE)\r\n\r\nlibrary(RColorBrewer)\r\nlibrary(sf)\r\nlibrary(spData)\r\nlibrary(spDataLarge)\r\nlibrary(tidyverse)\r\nlibrary(tmap)\r\nlibrary(dplyr)\r\n\r\n#display.brewer.all(colorblindFriendly = T) to view color-blind friendly palettes \r\n\r\n\r\n\r\nLoad, subset, and explore Asia data from spData world data\r\n\r\n\r\nshow\r\n\r\nworld_asia <- world[world[[\"continent\"]] == \"Asia\", ]\r\n\r\nplot(world_asia, max.plot = 10) #multi-plot of all attributes\r\n\r\n\r\n\r\nshow\r\n\r\nplot(world_asia[\"gdpPercap\"], #plot a specific attribute \r\n     key.pos = 4) #set the color key position (1=below, 2=left, 3=above and 4=right):\r\n\r\n\r\n\r\nshow\r\n\r\nplot(world_asia[\"gdpPercap\"], \r\n     key.pos = 1, \r\n     axes = TRUE, #add latitude/longitude tick marks \r\n     key.width = lcm(1.3), \r\n     key.length = 1.0)\r\n\r\n\r\n\r\n\r\nSpecify class intervals\r\n\r\n\r\nshow\r\n\r\nplot(world_asia[\"gdpPercap\"], nbreaks = 10)\r\n\r\n\r\n\r\nshow\r\n\r\n#nbreaks specifies the number of breaks\r\n#breaks uses a vector to specify break values or the break style \r\nplot(world_asia[\"gdpPercap\"], breaks = \"jenks\")\r\n\r\n\r\n\r\n\r\nAdd a graticule if necessary\r\n\r\n\r\nshow\r\n\r\nplot(world_asia[\"gdpPercap\"], graticule = TRUE, key.pos = NULL, axes = TRUE)\r\n\r\n\r\n\r\n\r\nHistogram of gdpPercap to choose breaks style\r\nboxplot to visualize data spread\r\n\r\n\r\nshow\r\n\r\nclass(world_asia$gdpPercap) #numeric class = continuous numeric variable \r\n\r\n\r\n[1] \"numeric\"\r\n\r\nshow\r\n\r\n#create a histogram, which shows a long right tail and strong skew \r\ngraphics::hist(world_asia$gdpPercap, \r\n     breaks = 10)\r\n\r\n\r\n\r\n\r\nPlot finished Asia map\r\n\r\n\r\nshow\r\n\r\n#create new bounding box \r\nbbox_new <- st_bbox(c(xmin = 26.04335, xmax = 145.5431,\r\n                      ymin = -15, ymax = 55.38525 )) # current bounding box\r\nxrange <- bbox_new$xmax - bbox_new$xmin # range of x values\r\nyrange <- bbox_new$ymax - bbox_new$ymin # range of y values\r\nbbox_new <- bbox_new %>%  \r\n  st_as_sfc()\r\n\r\n#plot \r\nasia_map <- tm_shape(world, bbox = bbox_new)+\r\n  tm_fill(col = \"white\") + \r\n  tm_borders(lwd = 0.1) + \r\ntm_shape(world_asia) +\r\n  tm_borders(lwd = 0.5) +\r\n  tm_fill(col = \"gdpPercap\", \r\n          palette = \"YlOrRd\", \r\n          style = \"order\",\r\n          title = \"GDP Per Capita\",\r\n          textNA = \"Missing Data\",\r\n          colorNA = \"gray\") +\r\n  tm_compass(type = \"4star\", \r\n             position = c(0.25,0.02), \r\n             size = 4, \r\n             show.labels = 2) + #show all 4 directions on the compass, not just N \r\n  #compass types: arrow, 4star, 8star, radar, rose\r\n  tm_scale_bar(breaks = c(0, 500, 1000, 1500, 2000), \r\n               text.size = 1, \r\n               position = c(\"center\", \"bottom\")) + \r\n  tm_text(text = \"name_long\", \r\n          size = 0.7, \r\n          col = \"black\") + \r\n  tm_layout(scale = 0.6, #zoom in and out \r\n            frame.lwd = 5,\r\n            legend.text.size = 1,\r\n            legend.title.size = 1.5, \r\n            legend.position = c(\"left\", \"bottom\"),\r\n            legend.bg.color = \"white\",\r\n            legend.frame = \"black\", \r\n            title.size = 2,\r\n            title.position = c(\"center\", \"top\"), \r\n            main.title = \"2014 GDP Per Capita in Asia\",\r\n            main.title.position = \"center\") +\r\n  tmap_options(bg.color = \"lightblue1\") + \r\n  tm_credits(paste(\"2014 GDP per capita for 43 countries in Asia. The mean per-capita GDP \\n was $20,026 (SD = 24,361; SE = 3,715). Original data is plotted in \\n WGS84 and sourced from 'spData' (https://nowosad.github.io/spData/).\"), \r\n             size = 0.8,\r\n             position=c(\"RIGHT\", \"BOTTOM\"),\r\n             bg.color = \"white\", \r\n             bg.alpha = 0.5)\r\nasia_map\r\n\r\n\r\n\r\n\r\nFigure 1: This map displays 2014 GDP per capita for 43 countries in Asia. 4 countries were omitted due to mising data: the Democratic People’s Republic of Korea, Northern Cyprus, Syria, and Taiwan. The maximum per-capita GDP is $120,860 in Qatar, and the minimum per-capita GDP is $1,839 in Afghanistan. The mean per-capita GDP is $20,026, and the median per-capita GDP is $10,650 (SD = 24,361; SE = 3,715). Only 4 countries measured per-capita GDP above $50,000. Per-capita GDP is rounded to the nearest whole number. Original world country polygon data is plotted in WGS84 and sourced from spData.\r\n\r\n\r\n\r\nshow\r\n\r\n#tmap_save(filename = \"asiamap_order.jpg\", width = 8, height = 5, units = \"in\", dpi = 300)\r\n\r\n\r\n\r\nGitHub\r\nFull code for this assignment can be found here.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-10-07-eds223cartography/asiamap.jpg",
    "last_modified": "2024-05-09T13:18:28-07:00",
    "input_file": {}
  }
]
